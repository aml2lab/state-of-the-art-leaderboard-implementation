conda activate rocm-pytorch
(base) john@llm-agents:~/open-source/py-proj/se-fashionmnist$ conda activate rocm-pytorch
(rocm-pytorch) john@llm-agents:~/open-source/py-proj/se-fashionmnist$ /home/john/miniconda3/envs/rocm-pytorch/bin/python /home/john/open-source/py-proj/se-fashionmnist/mnist_cnn_ensemble.py
Device: cuda
Total trainable params (3 nets): 1.382M
Epoch 1 [100/118] step=100 loss=1.3970 acc=65.09%
Epoch 1 done in 40.3s | train loss=1.3211 | acc=67.96%
W0813 23:03:00.970000 346536 site-packages/torch/_dynamo/convert_frame.py:906] [0/8] torch._dynamo hit config.cache_size_limit (8)
W0813 23:03:00.970000 346536 site-packages/torch/_dynamo/convert_frame.py:906] [0/8]    function: 'forward' (/home/john/open-source/py-proj/se-fashionmnist/mnist_cnn_ensemble.py:97)
W0813 23:03:00.970000 346536 site-packages/torch/_dynamo/convert_frame.py:906] [0/8]    last reason: 0/0: GLOBAL_STATE changed: grad_mode 
W0813 23:03:00.970000 346536 site-packages/torch/_dynamo/convert_frame.py:906] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0813 23:03:00.970000 346536 site-packages/torch/_dynamo/convert_frame.py:906] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
[val] epoch 1 | loss 0.3968 | acc 94.28%
Saved best checkpoint to mnist_ensemble_best.pth (acc=94.28%)
Epoch 2 [100/118] step=218 loss=0.5599 acc=91.53%
Epoch 2 done in 4.0s | train loss=0.5312 | acc=91.96%
[val] epoch 2 | loss 0.0968 | acc 98.13%
Saved best checkpoint to mnist_ensemble_best.pth (acc=98.13%)
Epoch 3 [100/118] step=336 loss=0.2767 acc=95.69%
Epoch 3 done in 2.0s | train loss=0.2690 | acc=95.78%
[val] epoch 3 | loss 0.0486 | acc 98.72%
Saved best checkpoint to mnist_ensemble_best.pth (acc=98.72%)
Epoch 4 [100/118] step=454 loss=0.2030 acc=96.64%
Epoch 4 done in 2.1s | train loss=0.1972 | acc=96.78%
[val] epoch 4 | loss 0.0324 | acc 98.97%
Saved best checkpoint to mnist_ensemble_best.pth (acc=98.97%)
Epoch 5 [100/118] step=572 loss=0.1662 acc=97.21%
Epoch 5 done in 2.1s | train loss=0.1638 | acc=97.28%
[val] epoch 5 | loss 0.0249 | acc 99.21%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.21%)
Epoch 6 [100/118] step=690 loss=0.1422 acc=97.65%
Epoch 6 done in 2.0s | train loss=0.1411 | acc=97.66%
[val] epoch 6 | loss 0.0224 | acc 99.27%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.27%)
Epoch 7 [100/118] step=808 loss=0.1212 acc=98.09%
Epoch 7 done in -43272.7s | train loss=0.1203 | acc=98.10%
[val] epoch 7 | loss 0.0195 | acc 99.32%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.32%)
Epoch 8 [100/118] step=926 loss=0.1098 acc=98.21%
Epoch 8 done in 2.1s | train loss=0.1093 | acc=98.19%
[val] epoch 8 | loss 0.0169 | acc 99.47%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.47%)
Epoch 9 [100/118] step=1044 loss=0.1014 acc=98.34%
Epoch 9 done in 2.1s | train loss=0.1001 | acc=98.37%
[val] epoch 9 | loss 0.0155 | acc 99.43%
Epoch 10 [100/118] step=1162 loss=0.0912 acc=98.55%
Epoch 10 done in 2.1s | train loss=0.0912 | acc=98.55%
[val] epoch 10 | loss 0.0158 | acc 99.45%
Epoch 11 [100/118] step=1280 loss=0.0863 acc=98.63%
Epoch 11 done in 2.1s | train loss=0.0862 | acc=98.61%
[val] epoch 11 | loss 0.0141 | acc 99.57%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.57%)
Epoch 12 [100/118] step=1398 loss=0.0810 acc=98.73%
Epoch 12 done in 2.1s | train loss=0.0815 | acc=98.70%
[val] epoch 12 | loss 0.0140 | acc 99.52%
Epoch 13 [100/118] step=1516 loss=0.0776 acc=98.74%
Epoch 13 done in 2.0s | train loss=0.0769 | acc=98.75%
[val] epoch 13 | loss 0.0126 | acc 99.55%
Epoch 14 [100/118] step=1634 loss=0.0723 acc=98.79%
Epoch 14 done in 2.0s | train loss=0.0720 | acc=98.82%
[val] epoch 14 | loss 0.0127 | acc 99.56%
Epoch 15 [100/118] step=1752 loss=0.0683 acc=98.93%
Epoch 15 done in 2.0s | train loss=0.0684 | acc=98.92%
[val] epoch 15 | loss 0.0121 | acc 99.60%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.60%)
Epoch 16 [100/118] step=1870 loss=0.0630 acc=98.98%
Epoch 16 done in 2.0s | train loss=0.0644 | acc=98.95%
[val] epoch 16 | loss 0.0108 | acc 99.65%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.65%)
Epoch 17 [100/118] step=1988 loss=0.0596 acc=99.07%
Epoch 17 done in 2.0s | train loss=0.0600 | acc=99.07%
[val] epoch 17 | loss 0.0113 | acc 99.57%
Epoch 18 [100/118] step=2106 loss=0.0609 acc=99.03%
Epoch 18 done in 2.0s | train loss=0.0613 | acc=99.02%
[val] epoch 18 | loss 0.0114 | acc 99.58%
Epoch 19 [100/118] step=2224 loss=0.0568 acc=99.06%
Epoch 19 done in 2.0s | train loss=0.0570 | acc=99.07%
[val] epoch 19 | loss 0.0107 | acc 99.66%
Saved best checkpoint to mnist_ensemble_best.pth (acc=99.66%)
Epoch 20 [100/118] step=2342 loss=0.0558 acc=99.13%
Epoch 20 done in 43276.9s | train loss=0.0553 | acc=99.14%
[val] epoch 20 | loss 0.0108 | acc 99.61%
Epoch 21 [100/118] step=2460 loss=0.0549 acc=99.16%
Epoch 21 done in 2.0s | train loss=0.0540 | acc=99.17%
[val] epoch 21 | loss 0.0104 | acc 99.63%
Epoch 22 [100/118] step=2578 loss=0.0517 acc=99.17%
Epoch 22 done in 2.0s | train loss=0.0518 | acc=99.19%
[val] epoch 22 | loss 0.0102 | acc 99.61%
Epoch 23 [100/118] step=2696 loss=0.0501 acc=99.19%
Epoch 23 done in 2.0s | train loss=0.0491 | acc=99.22%
[val] epoch 23 | loss 0.0102 | acc 99.62%
Epoch 24 [100/118] step=2814 loss=0.0496 acc=99.18%
Epoch 24 done in 2.0s | train loss=0.0490 | acc=99.20%
[val] epoch 24 | loss 0.0102 | acc 99.63%
Epoch 25 [100/118] step=2932 loss=0.0505 acc=99.16%
Epoch 25 done in 2.0s | train loss=0.0502 | acc=99.18%
[val] epoch 25 | loss 0.0103 | acc 99.60%
Training complete. Best val acc: 99.66%
elapsed: 101.1792984008789 seconds.
Warning: Resource leak detected by SharedSignalPool, 399 Signals leaked.
(rocm-pytorch) john@llm-agents:~/open-source/py-proj/se-fashionmnist$ 